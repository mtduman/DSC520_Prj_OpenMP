#!/bin/bash
#----------------------------------------------------
# Example SLURM job script to run MPI applications on 
# TACC's Stampede system.
#
# $Id: job.mpi 1580 2013-01-08 04:10:50Z karl $
#----------------------------------------------------

#SBATCH -J hw4_p3e9            # Job name
#SBATCH -o hw4_p3e9_%j.stdou   # Name of stdout output file (%j expands to jobId)
#SBATCH -e hostname_%j.err     # Name of stderr output file
#SBATCH -p development         # Queue name (development, normal, large > 256 nodes)
#SBATCH -N 1        percent           # Total number of nodes requested (16 cores/node)
#SBATCH -n 16                  # Total number of mpi tasks requested
#SBATCH -t 02:00:00            # Run time (hh:mm:ss) - 1.5 hours
#SBATCH -A TG-ASC160058        # Class allocation name to charge

# run your program 16 times in parallel (each one runs on a separate core)

EXE=/home1/04461/tg837609/umassd-hpc-mehmetduman/HW4/hw4_p9e        #/absolute/path/to/the/forward/euler/program

$EXE 16 100000000000 & # NOTE the "&" --> program runs in the background

wait # waits until all programs have finished
