#!/bin/bash
#----------------------------------------------------
# Example SLURM job script to run MPI applications on 
# TACC's Stampede system.
#
# $Id: job.mpi 1580 2013-01-08 04:10:50Z karl $
#----------------------------------------------------

#SBATCH -J hw4_p3d             # Job name
#SBATCH -o hw4_p3d_%j.stdou    # Name of stdout output file (%j expands to jobId)
#SBATCH -e hostname_%j.err     # Name of stderr output file
#SBATCH -p development         # Queue name (development, normal, large > 256 nodes)
#SBATCH -N 1                   # Total number of nodes requested (16 cores/node)
#SBATCH -n 16                  # Total number of mpi tasks requested
#SBATCH -t 00:05:00            # Run time (hh:mm:ss) - 1.5 hours
#SBATCH -A TG-ASC160058        # Class allocation name to charge

# run your program 16 times in parallel (each one runs on a separate core)

EXE=/home1/04461/tg837609/umassd-hpc-mehmetduman/HW4/hw4_p3abcd        #/absolute/path/to/the/forward/euler/program

$EXE 1 1000000 & # NOTE the "&" --> program runs in the background
$EXE 2 1000000 &
$EXE 4 1000000 &
$EXE 8 1000000 &
$EXE 16 1000000 &

wait # waits until all programs have finished
